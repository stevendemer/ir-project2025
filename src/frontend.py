import matplotlib.pyplot as plt

import streamlit as st
import requests
import pandas as pd
import altair as alt
import os

st.set_page_config(page_title="Parliament Analytics", page_icon="ðŸ›ï¸", layout="wide")

@st.cache_resource
def load_analytics():

    try:
        from analytics import AnalyticsEngine
    except ImportError:
        import sys
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from src.analytics import AnalyticsEngine
    
    current_script_dir = os.path.dirname(os.path.abspath(__file__))

    project_root = os.path.dirname(current_script_dir)

    data_path = os.path.join(project_root, "data", "cleaned_data.parquet")

    print(f'Loading data from {data_path}')

    return AnalyticsEngine(data_path)

try:
    analytics_engine = load_analytics()
except Exception as e:
    st.error(f"Error loading analytics: {e}")
    analytics_engine = None

st.title("ðŸ›ï¸ Î•Î»Î»Î·Î½Î¹ÎºÏŒ ÎšÎ¿Î¹Î½Î¿Î²Î¿ÏÎ»Î¹Î¿: Insights & Search")

tab1, tab2 = st.tabs(["ðŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ·", "ðŸ“Š Î‘Î½Î¬Î»Ï…ÏƒÎ· Keywords"])

with tab1:
    st.subheader("ÎœÎ·Ï‡Î±Î½Î® Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚")
    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_input("Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ ÏŒÏÎ¿ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚:", placeholder="Ï€.Ï‡. Ï€Î±Î¹Î´ÎµÎ¯Î±")
    with col2:
        limit = st.slider("Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±", 5, 50, 5)

    if st.button("Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ·", key="search_btn") or query:
        try:
            response = requests.get(f"http://127.0.0.1:8000/search", params={"query": query, "limit": limit})
            if response.status_code == 200:
                results = response.json().get("results", [])
                st.write(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(results)} Î¿Î¼Î¹Î»Î¯ÎµÏ‚.")
                
                for res in results:
                    with st.expander(f"{res.get('member_name')} ({res.get('sitting_date')}) - Score: {res.get('similarity_score')}"):
                        st.write(f"**ÎšÏŒÎ¼Î¼Î±:** {res.get('political_party')}")
                        st.text(res.get('speech')[:1000] + "...")
            else:
                st.error("Error connecting to Backend API.")
        except:
            st.error("ÎŸ Server Î´ÎµÎ½ Î±Î½Ï„Î±Ï€Î¿ÎºÏÎ¯Î½ÎµÏ„Î±Î¹. Î¤ÏÎ­Ï‡ÎµÎ¹ Ï„Î¿ uvicorn;")

with tab2:
    if analytics_engine:
        st.header("Î¤Î¬ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î›Î­Î¾ÎµÎ¹Ï‚-ÎšÎ»ÎµÎ¹Î´Î¹Î¬")
        
        mode = st.radio("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î‘Î½Î¬Î»Ï…ÏƒÎ·:", 
                ["Top Keywords Î±Î½Î¬ ÎšÏŒÎ¼Î¼Î±", "Top Keywords Î±Î½Î¬ ÎˆÏ„Î¿Ï‚", 
                 "Î”Î¹Î±Ï‡ÏÎ¿Î½Î¹ÎºÎ® Î•Î¾Î­Î»Î¹Î¾Î· Î›Î­Î¾Î·Ï‚", "ÎŸÎ¼Î¿Î¹ÏŒÏ„Î·Ï„Î± Î’Î¿Ï…Î»ÎµÏ…Ï„ÏŽÎ½", "Î˜ÎµÎ¼Î±Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· (LSI)", "Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚"], horizontal=True)
        
        if mode == "Top Keywords Î±Î½Î¬ ÎšÏŒÎ¼Î¼Î±":
            st.markdown("ÎŸÎ¹ Î»Î­Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ ÎºÎ¬Î¸Îµ ÎºÏŒÎ¼Î¼Î± **Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿ Î±Ï€ÏŒ Ï„Î± Î¬Î»Î»Î±**.")
            
            if st.button("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ (Party Analysis)"):
                with st.spinner("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ TF-IDF Î±Î½Î¬ ÎºÏŒÎ¼Î¼Î±..."):
                    # ÎšÎ±Î»Î¿ÏÎ¼Îµ Ï„Î· ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î±Ï€ÏŒ Ï„Î¿ analytics.py
                    keywords_dict = analytics_engine.get_keywords_by_group('political_party')
                    
                    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
                    for party, words in keywords_dict.items():
                        # Î”ÎµÎ¯Ï‡Î½Î¿Ï…Î¼Îµ Î¼ÏŒÎ½Î¿ Ï„Î± Î¼ÎµÎ³Î¬Î»Î± ÎºÏŒÎ¼Î¼Î±Ï„Î± Î³Î¹Î± Î½Î± Î¼Î·Î½ Î³ÎµÎ¼Î¯ÏƒÎµÎ¹ Î· Î¿Î¸ÏŒÎ½Î·
                        if len(words) > 0:
                            st.subheader(party)
                            # Î¦Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î­Î½Î± Î¼Î¹ÎºÏÏŒ dataframe Î³Î¹Î± Ï„Î¿ chart
                            df_chart = pd.DataFrame(words, columns=["Word", "Score"])
                            
                            # Bar chart Î¼Îµ Altair
                            c = alt.Chart(df_chart).mark_bar().encode(
                                x='Score',
                                y=alt.Y('Word', sort='-x'),
                                color=alt.value('teal')
                            )
                            st.altair_chart(c, use_container_width=True)

        elif mode == "Top Keywords Î±Î½Î¬ ÎˆÏ„Î¿Ï‚":
            st.markdown("Î¤Î¹ ÏƒÏ…Î¶Î·Ï„Î®Î¸Î·ÎºÎµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ¿ ÎºÎ¬Î¸Îµ Ï‡ÏÎ¿Î½Î¹Î¬;")

            if st.button("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ (Yearly Analysis)"):
                with st.spinner("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚..."):

                    st.session_state['yearly_keywords'] = analytics_engine.get_keywords_by_group('year')
                
                if 'yearly_keywords' in st.session_state:

                    keywords_dict = st.session_state['yearly_keywords']

                    # Dropdown Î³Î¹Î± Î½Î± Î´Î¹Î±Î»Î­Î¾ÎµÎ¹ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Î­Ï„Î¿Ï‚ - ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Ï‚ ÏƒÏ„Î± ÎµÏ„Î· Î½Î± Î¼Î·Î½ Ï†Î±Î¹Î½ÎµÏ„Î±Î¹ 2024.0
                    years = [int(y) for y in keywords_dict.keys() if str(y) != 'nan' and y > 0]
                    years = sorted(years, reverse=True)

                    if not years:
                        st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î­Ï„Î· ÏƒÏ„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")
                    else:
                        selected_year = st.selectbox("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Î­Ï„Î¿Ï‚", years)

                        if selected_year:
                            words = keywords_dict.get(selected_year) or keywords_dict.get(float(selected_year))

                            if words:
                                df_chart = pd.DataFrame(words, columns=["Word", "Score"])

                                c = alt.Chart(df_chart).mark_bar().encode(
                                    x='Score',
                                    y=alt.Y('Word', sort='-x'),
                                    color=alt.value('orange')
                                )
                                st.altair_chart(c, use_container_width=True)
                            else:
                                st.warning(f'Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ keywords Î³Î¹Î± Ï„Î¿ {selected_year}')

        elif mode == "Î”Î¹Î±Ï‡ÏÎ¿Î½Î¹ÎºÎ® Î•Î¾Î­Î»Î¹Î¾Î· Î›Î­Î¾Î·Ï‚":
            st.subheader("Trend Analysis")
            target_word = st.text_input("Î›Î­Î¾Î· Ï€ÏÎ¿Ï‚ Î±Î½Î¬Î»Ï…ÏƒÎ·:", "Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¯Î±")
            
            if target_word:
                stripped_word = target_word.lower().strip()
                
                timeline_data = analytics_engine.get_keywords_timeline(stripped_word)
                
                if not timeline_data.empty:
                    st.line_chart(timeline_data)
                    st.caption("Î Î¿ÏƒÎ¿ÏƒÏ„ÏŒ (%) Î¿Î¼Î¹Î»Î¹ÏŽÎ½ Ï€Î¿Ï… Ï€ÎµÏÎ¹Î­Ï‡Î¿Ï…Î½ Ï„Î· Î»Î­Î¾Î·.")
                else:
                    st.warning("Î— Î»Î­Î¾Î· Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î® Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÏÎºÎµÏ„Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")

        elif mode == "ÎŸÎ¼Î¿Î¹ÏŒÏ„Î·Ï„Î± Î’Î¿Ï…Î»ÎµÏ…Ï„ÏŽÎ½":
            st.markdown("Î Î¿Î¹Î¿Î¹ Î²Î¿Ï…Î»ÎµÏ…Ï„Î­Ï‚ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î¿ÏÎ½ Ï€Î±ÏÏŒÎ¼Î¿Î¹Î¿ Î»ÎµÎ¾Î¹Î»ÏŒÎ³Î¹Î¿;")
            st.info("âš ï¸ Î ÏÎ¿ÏƒÎ¿Ï‡Î®: Î¥Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÏ„Î±Î¹ Î· Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î± Î²Î¬ÏƒÎµÎ¹ Ï„Ï‰Î½ Î¿Î¼Î¹Î»Î¹ÏŽÎ½ (Cosine Similarity).")
            
            top_k = st.slider("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î–ÎµÏ…Î³Î±ÏÎ¹ÏŽÎ½", 5, 50, 10)
            
            if st.button("Î•ÏÏÎµÏƒÎ· Î–ÎµÏ…Î³ÏŽÎ½"):
                with st.spinner("Î£Ï…Î³ÎºÏÎ¯Î½Î¿Ï…Î¼Îµ Ï„Î¿Ï…Ï‚ Î²Î¿Ï…Î»ÎµÏ…Ï„Î­Ï‚ Î¼ÎµÏ„Î±Î¾Ï Ï„Î¿Ï…Ï‚..."):
                    pairs = analytics_engine.get_top_similar_pairs(top_k=top_k)
                    
                    if pairs:
                        st.write(f"Î¤Î± {top_k} Î¶ÎµÏ…Î³Î¬ÏÎ¹Î± Î¼Îµ Ï„Î· Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ· Î¿Î¼Î¿Î¹ÏŒÏ„Î·Ï„Î±:")

                        cmap = plt.colormaps['Greens']
                        
                        # Î©ÏÎ±Î¯Î± ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Î¼Îµ Ï€Î¯Î½Î±ÎºÎ±
                        df_pairs = pd.DataFrame(pairs)
                        st.dataframe(
                            df_pairs.style.background_gradient(subset=['Similarity'], cmap=cmap),
                            width='stretch'
                        )
                    else:
                        st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î±ÏÎºÎµÏ„Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÏƒÏÎ³ÎºÏÎ¹ÏƒÎ·.")

        elif mode == "Î˜ÎµÎ¼Î±Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· (LSI)":
            st.markdown("Î‘Î½Î±ÎºÎ¬Î»Ï…ÏˆÎ· ÎºÏÏ…Î¼Î¼Î­Î½Ï‰Î½ Î¸ÎµÎ¼Î±Ï„Î¹ÎºÏŽÎ½ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ (Topics) Î¼Îµ Ï‡ÏÎ®ÏƒÎ· SVD.")
            
            n_topics = st.slider("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î˜ÎµÎ¼Î¬Ï„Ï‰Î½ (Topics)", 3, 10, 5)
            
            if st.button("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î˜ÎµÎ¼Î¬Ï„Ï‰Î½"):
                with st.spinner("Î•ÎºÏ„Î­Î»ÎµÏƒÎ· LSI (Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€Î¬ÏÎµÎ¹ Î»Î¯Î³Î¿ Ï‡ÏÏŒÎ½Î¿)..."):
                    topics = analytics_engine.perform_lsi(n_topics=n_topics)
                    
                    st.success("Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏŽÎ¸Î·ÎºÎµ!")
                    
                    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Ï‰Î½ Î¸ÎµÎ¼Î¬Ï„Ï‰Î½ Î¼Îµ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î±
                    for topic_name, words in topics.items():
                        st.divider()
                        st.subheader(f"ðŸ“Œ {topic_name}")
                        
                        # Î¦Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î»Î­Î¾ÎµÎ¹Ï‚ "ÎµÏ„Î¹ÎºÎ­Ï„ÎµÏ‚" Î³Î¹Î± Î½Î± Ï†Î±Î¯Î½ÎµÏ„Î±Î¹ Ï„Î¹ Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ Ï„Î¿ Î¸Î­Î¼Î±
                        keywords_str = ", ".join([w[0] for w in words[:5]])
                        st.caption(f"ÎšÏÏÎ¹ÎµÏ‚ Î»Î­Î¾ÎµÎ¹Ï‚: {keywords_str}...")
                        
                        # DataFrame Î³Î¹Î± Ï„Î¿ Î³ÏÎ¬Ï†Î·Î¼Î±
                        df_topic = pd.DataFrame(words, columns=["Word", "Weight"])
                        
                        # ÎŸÏÎ¹Î¶ÏŒÎ½Ï„Î¹Î¿ Bar Chart
                        c = alt.Chart(df_topic).mark_bar().encode(
                            x='Weight',
                            y=alt.Y('Word', sort='-x'),
                            color=alt.value('#6c5ce7'), # ÎœÏ‰Î² Ï‡ÏÏŽÎ¼Î±
                            tooltip=['Word', 'Weight']
                        ).properties(height=300)
                        
                        st.altair_chart(c, use_container_width=True)
        elif mode == 'Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚':
            st.subheader("Î‘Î½Î¬Î»Ï…ÏƒÎ· Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚ Î±Î½Î¬ ÎšÏŒÎ¼Î¼Î±")
            st.markdown("""
            **Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®:** Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Î¼Î­ÏƒÎ¿Ï… ÏƒÏ…Î½Î±Î¹ÏƒÎ¸Î·Î¼Î±Ï„Î¹ÎºÎ¿Ï Ï†Î¿ÏÏ„Î¯Î¿Ï… Ï„Ï‰Î½ Î¿Î¼Î¹Î»Î¹ÏŽÎ½ ÎºÎ¬Î¸Îµ ÎºÏŒÎ¼Î¼Î±Ï„Î¿Ï‚ 
            Î²Î¬ÏƒÎµÎ¹ Î»ÎµÎ¾Î¹ÎºÎ¿Ï Î¸ÎµÏ„Î¹ÎºÏŽÎ½ ÎºÎ±Î¹ Î±ÏÎ½Î·Ï„Î¹ÎºÏŽÎ½ Î»Î­Î¾ÎµÏ‰Î½.
            - **Î˜ÎµÏ„Î¹ÎºÏŒ ÏƒÎºÎ¿Ï:** Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î»Î­Î¾ÎµÎ¹Ï‚ ÏŒÏ€Ï‰Ï‚ "Î±Î½Î¬Ï€Ï„Ï…Î¾Î·", "Ï€ÏÏŒÎ¿Î´Î¿Ï‚".
            - **Î‘ÏÎ½Î·Ï„Î¹ÎºÏŒ ÏƒÎºÎ¿Ï:** Î ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎµÏ‚ Î»Î­Î¾ÎµÎ¹Ï‚ ÏŒÏ€Ï‰Ï‚ "ÎºÏÎ¯ÏƒÎ·", "Ï‡ÏÎ­Î¿Ï‚".
            """)

            if st.button("Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î£Ï…Î½Î±Î¹ÏƒÎ¸Î®Î¼Î±Ï„Î¿Ï‚"):
                with st.spinner("Analyzing sentiment..."):
                    sentiment_scores = analytics_engine.get_sentiment_by_party()
                    
                    df_sent = sentiment_scores.reset_index()
                    df_sent.columns = ['Political Party', 'Sentiment Score']

                    
                    c = alt.Chart(df_sent).mark_bar().encode(
                        x=alt.X("Political Party", sort='-y'),
                        y='Sentiment Score',
                        color=alt.condition(
                            alt.datum['Sentiment Score'] > 0,
                            alt.value('#2ecc71'),  # Green for positive
                            alt.value('#e74c3c')   # Red for negative
                        ),
                        tooltip=['Political Party', 'Sentiment Score']
                    ).properties(height=400)

                    st.altair_chart(c, use_container_width=True)
                    
                    st.dataframe(df_sent.style.background_gradient(cmap="RdYlGn", subset=['Sentiment Score']))
    else:
        st.warning("Analytics Engine could not be loaded.")